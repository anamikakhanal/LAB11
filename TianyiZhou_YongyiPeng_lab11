---
title: "TianyiZhou&Sophie(Yongyi) Peng"
output: html_document
date:10/10/2019
---

```{r}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
data <- read.csv("~/stat340/LAB11/class11_LAB_dataFrame_20190930T2158.csv")
print(data)
```

####Exploratory Data Analysis
(1) PLot y VS. x
```{r}
plot(data$x,data$y)
model1 <- lm(y~x,data=data)
lines(data$x,predict.lm(model1,data.frame(x=data$x)),col='red')
```
The relationship between x and y is non-linear. The relatinoship between x and y seems like a curve.

(2) PLot y VS. a
```{r}
plot(data$a,data$y)
model2 <- lm(y~a,data=data)
lines(data$a,predict.lm(model2,data.frame(a=data$a)),col='red')
```
The relationship between a and y doesn't seem very linear.

(3) PLot y VS. b
```{r}
plot(data$b,data$y)
model3 <- lm(y~b,data=data)
lines(data$b,predict.lm(model3,data.frame(b=data$b)),col='red')

```
The relationship betwen b and y looks like a triangle, but not too bad since the most of the datapoints form a line shape instead of a curve shape.

(4) PLot y VS. c
```{r}
plot(data$c,data$y)
model4 <- lm(y~c,data=data)
lines(data$c,predict.lm(model4,data.frame(c=data$c)),col='red')

```
The relationship between  y and c is somehow linear. Not too bad.

####Regression
Simple Linear Regression model for y and a AND the scatterplot:
```{r}
plot(data$a,data$y)
model2 <- lm(y~a,data=data)
lines(data$a,predict.lm(model2,data.frame(a=data$a)),col='red')
summary(model2)
```
Model for y and a is predicted y =  -4.641 + 6.195 * a
This model has high bias, it does not capture the fluatuation of variable a.


####Transformation

Transform a in 4 different ways: log, a^0.5, a^0.333, a^0.25
```{r}


options(repr.plot.width=7*1, repr.plot.height=7)
par(mfrow=c(2,2))

transformeda = log(data$a)
plot(transformeda,data$y,xlab='log(a)',ylab='y',tck = 0.02)
modelTF <- lm(y~log(a),data=data)
predictions <- predict.lm(modelTF,data.frame(a=data$a))
lines(transformeda
      ,predictions
      ,col='red')
summary(modelTF)


transformeda = (data$a)^0.5
plot(data$a^0.5,data$y,xlab='a^0.5',ylab='y',tck = 0.02)
modelTF <- lm(y~I(a^0.5),data=data)

predictions <- predict.lm(modelTF,data.frame(a=data$a))
lines(transformeda
      ,predictions
      ,col='red')
summary(modelTF)




transformeda = (data$a)^0.333
plot(data$a^0.333,data$y,xlab='a^1/3',ylab='y',tck = 0.02)
modelTF <- lm(y~I(a^0.333),data=data)

predictions <- predict.lm(modelTF,data.frame(a=data$a))
lines(transformeda
      ,predictions
      ,col='red')
summary(modelTF)




transformeda = (data$a)^0.25
plot(data$a^0.25,data$y,xlab='a^0.25',ylab='y',tck = 0.02)
modelTF <- lm(y~I(a^0.25),data=data)

predictions <- predict.lm(modelTF,data.frame(a=data$a))
lines(transformeda
      ,predictions
      ,col='red')
summary(modelTF)
```
There's one model missed. This is kind of normal since not all transformation will work. 

Simple Linear Regression modelTF - log(a):
Model for y and log(a) is predicted y =  0.6584 + 9.8299 * log(a)

Simple Linear Regression modelTF - I(a^0.5):
Model for y and I(a^0.5) is predicted y =  -14.47 + 15.61 * I(a^0.5) 

Simple Linear Regression modelTF - I(a^0.333):
Model for y and I(a^0.333) is predicted y =  -24.33 + 25.32 * I(a^0.333)

Simple Linear Regression modelTF - I(a^0.25):
Model for y and I(a^0.25) is predicted y =  -34.13 + 35.04 * I(a^0.25)

####Residuals:
Error distribution:
```{r}
options(repr.plot.width=8, repr.plot.height=8)
par(mfrow=c(2,2))

modelLog <- lm(y~log(a),data=data)
epsilonsLog <- residuals(modelLog)
hist(epsilonsLog,col='blue',main="log(a)")

modelHalf <- lm(y~I(a^0.5),data=data)
epsilonsHalf <- residuals(modelHalf)
hist(epsilonsHalf,col='blue',main="a^0.50")


modelThird <- lm(y~I(a^0.33),data=data)
epsilonsThird <- residuals(modelThird)
hist(epsilonsThird,col='blue',main="a^0.33")


modelQuarter <- lm(y~I(a^0.25),data=data)
epsilonsQuarter <- residuals(modelQuarter)
hist(epsilonsQuarter,col='blue',main="a^0.25")



```
The error distribution is very similar between all three transformations. All transformation's errors are between -10 and 15. Comparing histograms is difficult. We only have the error distribution of three transformations since one of the transformation didn't work.

#### QQ
QQ plot of above 4 model residuals
```{r}

options(repr.plot.width=8*1, repr.plot.height=8)

normalSample <- rnorm(100,0,4)
varSample <- var(normalSample)
meanSample <- mean(normalSample)

probs <- seq(1,100,1)/100 

theoreticalNormals <- qnorm(probs,meanSample,varSample)  

plot(theoreticalNormals,sort(normalSample)
     ,xlab='Theoretical Normal'
     ,ylab='Empirical Distribution'
     ,tck=0.01)

data <- data.frame("sample" =sort(normalSample), "theory"=theoreticalNormals) 
model = lm(sample~theory,data=data[30:70,])
abline(model,col='red')
```

```{r}
par(mfrow=c(2,2))

# plot 1
epsilonsLog = sort(epsilonsLog)
N = length(epsilonsLog)
probs = seq(1,N)/(N+1)
theoreticalNormal = qnorm(probs)

plot(theoreticalNormal,epsilonsLog
     ,xlab='Theoretical Normal'
     ,ylab='Empirical Normal')
abline(lm(epsilonsLog~theoreticalNormal))
title('log')


# plot 2
epsilonsHalf = sort(epsilonsHalf)
N = length(epsilonsHalf)
probs = seq(1,N)/(N+1)
theoreticalNormal = qnorm(probs)

plot(theoreticalNormal,epsilonsHalf
     ,xlab='Theoretical Normal'
     ,ylab='Empirical Normal')
abline(lm(epsilonsHalf~theoreticalNormal))
title('x^1/2')


# plot 3
epsilonsThird = sort(epsilonsThird)
N = length(epsilonsThird)
probs = seq(1,N)/(N+1)
theoreticalNormal = qnorm(probs)

plot(theoreticalNormal,epsilonsThird
     ,xlab='Theoretical Normal'
     ,ylab='Empirical Normal')
abline(lm(epsilonsThird~theoreticalNormal))


# plot 4
epsilonsQuarter = sort(epsilonsQuarter)
N = length(epsilonsQuarter)
probs = seq(1,N)/(N+1)
theoreticalNormal = qnorm(probs)

plot(theoreticalNormal,epsilonsQuarter
     ,xlab='Theoretical Normal'
     ,ylab='Empirical Normal')
abline(lm(epsilonsQuarter~theoreticalNormal))
```
The QQ plots of 3 different transformation looks exactly the same. We only have 3 QQ plots here since one of the transformations didn't work.


Equality of Variance
```{r}
par(mfrow=c(2,2))

# plot 1
modelLog <- lm(y~log(a),data=data)
epsilonsLog <- residuals(modelLog)

plot(data$x,epsilonsLog, tck=0.01)
title('log(a)')

# plot 2
modelHalf <- lm(y~I(a^0.5),data=data)
epsilonsHalf <- residuals(modelHalf)

plot(data$x,epsilonsHalf, tck=0.01)
title('a^1/2')

# plot 3
modelThird <- lm(y~I(a^0.33),data=data)
epsilonsThird <- residuals(modelThird)

plot(data$x,epsilonsThird, tck=0.01)
title('a^1/3')

# plot 4
modelQuarter <- lm(y~I(a^0.25),data=data)
epsilonsQuarter <- residuals(modelQuarter)

plot(data$x,epsilonsQuarter, tck=0.01)
title('a^1/4')
```
These three graphs also looks exactly the same. 

####Multiple Linear Relationship

```{r}
MLRmodel <- lm(y ~ x + a + b + c, data=data)
plot(MLRmodel)
summary(MLRmodel)


```
The Multiple Linear Regression model between y and (x,a,b,c) is predicted y = 6.5123 +  3.0016 * x - 1.2917*a - 0.2199 * b - 0.2159 * c


```{r}

options(repr.plot.width=8, repr.plot.height=8)
par(mfrow=c(2,2))

MLRmodel <- lm(y ~ x + a + b + c, data=data)
epsilons <- residuals(MLRmodel)
hist(epsilons, col='blue',main="(x,a,b,c)")

```
LINE Assumption:

L- linear relationship: Not satisfied. The relationship beteen (x,a,b,c) and y is not very linear, especially the relationship between x and y. 

I - independent observations: Satisfied.

N - normal distribution of error. The QQ-plot seems not bad. Somehow satisfied.

E - equal variance of error. The scatterplot between x and errors seems not too bad, but there's a slightly curve tendency between (x,a,b,c) and y. Somehow Satisfied.

For variable x,  we recommend apply exponential transformation.
For variable a,  we recommend not to apply transformation.
For variable b,  we recommend apply a quadratic transformation.
For variable c,  we recommend not to transform

We choose to transform variable x, since the relationship between x and y appears non-linear. It breaks the L assumption.

#### Exponential Transformation of x

```{r}

transformedx = exp(data$x)
plot(exp(data$x),data$y,xlab='e^x',ylab='y',tck = 0.02)
modelTF <- lm(y~I(exp(x)),data=data)

predictions <- predict.lm(modelTF,data.frame(x=data$x))
lines(transformedx
      ,predictions
      ,col='red')
summary(modelTF)

```

The exponential transformation works pretty well for x. The relationship between e^x and y is linear. Transforming variable x does help. Now, the linear assumption is satisfied.


